{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZHogYqw9OaS"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "kazanova_sentiment140_path = kagglehub.dataset_download('kazanova/sentiment140')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u872KlA-9OaU"
      },
      "source": [
        "#  Step 1: Prepare the work environment\n",
        "📌 We install essential tools for data analysis (Pandas, NumPy), visualization (Matplotlib, Seaborn), machine learning (Scikit-learn), and language processing (nltk)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-07-06T11:21:30.332184Z",
          "iopub.status.busy": "2025-07-06T11:21:30.331731Z",
          "iopub.status.idle": "2025-07-06T11:21:34.161723Z",
          "shell.execute_reply": "2025-07-06T11:21:34.160783Z",
          "shell.execute_reply.started": "2025-07-06T11:21:30.33216Z"
        },
        "id": "nZCnOIxA9OaV",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install pandas numpy matplotlib seaborn scikit-learn nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVqhY_2l9OaW"
      },
      "source": [
        "# ✨ Step 2: Upload and process data\n",
        "📌 We uploaded the file, renamed the columns, removed the unnecessary ones, and finally converted the numbers to understandable labels (negative/neutral/positive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T11:23:06.238019Z",
          "iopub.status.busy": "2025-07-06T11:23:06.237237Z",
          "iopub.status.idle": "2025-07-06T11:23:13.769803Z",
          "shell.execute_reply": "2025-07-06T11:23:13.76922Z",
          "shell.execute_reply.started": "2025-07-06T11:23:06.237967Z"
        },
        "id": "FLABWnYd9OaW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv',\n",
        "                 encoding='latin-1', header=None)\n",
        "\n",
        "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
        "df = df[['target', 'text']]\n",
        "df['target'] = df['target'].replace({0: 'negative', 2: 'neutral', 4: 'positive'})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEAt7h0g9OaX"
      },
      "source": [
        "# ✨ Step 3: Clean up texts\n",
        "📌 Here we prepare the text for learning: remove links, symbols, and hashtags, and make the letters lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T11:23:40.987627Z",
          "iopub.status.busy": "2025-07-06T11:23:40.987356Z",
          "iopub.status.idle": "2025-07-06T11:23:48.222665Z",
          "shell.execute_reply": "2025-07-06T11:23:48.22215Z",
          "shell.execute_reply.started": "2025-07-06T11:23:40.987607Z"
        },
        "id": "MH0sS7M39OaX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove links\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)     # Remove the mention\n",
        "    text = re.sub(r\"#\", \"\", text)        # Remove hashtag\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove symbols\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBDJ9To19OaY"
      },
      "source": [
        "# ✨ Step 4: Convert text to digital vector (TF-IDF Vectorizer)\n",
        "📌 We use TF-IDF technology to convert words into numbers that algorithms can understand. We exclude common words (stopwords) and identify only 10,000 features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T11:28:11.095894Z",
          "iopub.status.busy": "2025-07-06T11:28:11.095233Z",
          "iopub.status.idle": "2025-07-06T11:28:27.703974Z",
          "shell.execute_reply": "2025-07-06T11:28:27.703434Z",
          "shell.execute_reply.started": "2025-07-06T11:28:11.095869Z"
        },
        "id": "AOS0PgEv9OaY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words, max_features=10000)\n",
        "X = vectorizer.fit_transform(df['cleaned_text'])\n",
        "y = df['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8ALBuMS9OaY"
      },
      "source": [
        "# ✨ Step 5: Splitting the data to train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T11:28:56.295633Z",
          "iopub.status.busy": "2025-07-06T11:28:56.295226Z",
          "iopub.status.idle": "2025-07-06T11:29:25.832473Z",
          "shell.execute_reply": "2025-07-06T11:29:25.831206Z",
          "shell.execute_reply.started": "2025-07-06T11:28:56.29561Z"
        },
        "id": "F8Sg4OJE9OaZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTd8uwQs9OaZ"
      },
      "source": [
        "# ✨ Step 6: Evaluate the model\n",
        "📌 Here we evaluate the model's performance using classification accuracy, balancing precision and recall for each type of emotion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T11:29:39.750169Z",
          "iopub.status.busy": "2025-07-06T11:29:39.749561Z",
          "iopub.status.idle": "2025-07-06T11:29:51.796444Z",
          "shell.execute_reply": "2025-07-06T11:29:51.795807Z",
          "shell.execute_reply.started": "2025-07-06T11:29:39.750141Z"
        },
        "id": "ZxjTx8s89Oaa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T11:30:57.666125Z",
          "iopub.status.busy": "2025-07-06T11:30:57.665535Z",
          "iopub.status.idle": "2025-07-06T11:30:58.789953Z",
          "shell.execute_reply": "2025-07-06T11:30:58.789351Z",
          "shell.execute_reply.started": "2025-07-06T11:30:57.666101Z"
        },
        "id": "eKyEw8Ty9Oaa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'sentiment_model.pkl')\n",
        "\n",
        "# Save the vectorizer\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T11:50:38.061089Z",
          "iopub.status.busy": "2025-07-06T11:50:38.060587Z",
          "iopub.status.idle": "2025-07-06T11:50:39.213535Z",
          "shell.execute_reply": "2025-07-06T11:50:39.212775Z",
          "shell.execute_reply.started": "2025-07-06T11:50:38.061059Z"
        },
        "id": "L7sf0QaM9Oaa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'sentiment_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj2R3eYI9Oaa"
      },
      "source": [
        "# ✨ Step 7: Create a Gradio App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-07-06T11:55:36.804591Z",
          "iopub.status.busy": "2025-07-06T11:55:36.804267Z",
          "iopub.status.idle": "2025-07-06T11:55:39.991395Z",
          "shell.execute_reply": "2025-07-06T11:55:39.990645Z",
          "shell.execute_reply.started": "2025-07-06T11:55:36.80457Z"
        },
        "id": "xLHlT_HI9Oaa",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#install gradio\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-06T11:53:38.280009Z",
          "iopub.status.busy": "2025-07-06T11:53:38.279216Z",
          "iopub.status.idle": "2025-07-06T11:53:39.550383Z",
          "shell.execute_reply": "2025-07-06T11:53:39.549827Z",
          "shell.execute_reply.started": "2025-07-06T11:53:38.27998Z"
        },
        "id": "RWdpGMgJ9Oab",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import joblib\n",
        "import re\n",
        "\n",
        "# Load the model and TF-IDF vectorizer\n",
        "model = joblib.load(\"sentiment_model.pkl\")\n",
        "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+|@\\w+|#\", \"\", text)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    return text.lower()\n",
        "\n",
        "# Sentiment prediction function\n",
        "def predict_sentiment(text):\n",
        "    cleaned = clean_text(text)\n",
        "    vectorized = vectorizer.transform([cleaned])\n",
        "    prediction = model.predict(vectorized)[0]\n",
        "    if prediction == \"positive\":\n",
        "        return \"🎉 Sentiment: Positive\"\n",
        "    elif prediction == \"negative\":\n",
        "        return \"😠 Sentiment: Negative\"\n",
        "    else:\n",
        "        return \"😐 Sentiment: Neutral\"\n",
        "\n",
        "# Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_sentiment,\n",
        "    inputs=gr.Textbox(lines=3, label=\"📝 Enter Tweet Text\"),\n",
        "    outputs=gr.Textbox(label=\"Prediction\"),\n",
        "    title=\"🔍 Twitter Sentiment Analyzer\",\n",
        "    description=\"Analyze the sentiment of tweets: Positive, Negative, or Neutral\"\n",
        ")\n",
        "\n",
        "# Run locally\n",
        "if __name__ == \"__main__\":\n",
        "    interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4G6GDuc9Oab",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#the end"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "twitter-sentiment-analysis-gradio",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 2477,
          "sourceId": 4140,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
